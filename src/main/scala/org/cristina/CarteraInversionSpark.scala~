package org.dummy

import org.apache.spark.mllib.linalg.{Vector,DenseVector,Vectors}
import org.apache.spark.SparkContext
import org.apache.spark.mllib.recommendation.{ALS,Rating,MatrixFactorizationModel}
import org.apache.spark.mllib.linalg.{Matrix,Matrices}
import org.apache.spark.mllib.linalg.distributed.{RowMatrix, CoordinateMatrix, MatrixEntry}
import org.apache.spark.rdd.RDD
import org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}
import scala.language.implicitConversions
import breeze.linalg.{squaredDistance}
import org.apache.spark.SparkConf



/**
 * Created by cloudera on 6/23/15.
 */
object CarteraInversionSpark{

  def main(args: Array[String]){

  val sc = new SparkContext("local","CI")
  val file = sc.textFile("/home/cloudera/Desktop/CarteraInversionSpark/CI10.txt")
  val num_data = file.map(line => line.split('\t').tail.map(x=>x.toDouble))
  val v = num_data.map(line=> Vectors.dense(line))
  val x = new RowMatrix(v)
  val m = x.computeCovariance()
  
  
  
  //sc.makeRDD(m.toArray,1).saveAsTextFile("salida100")
 

}

}


